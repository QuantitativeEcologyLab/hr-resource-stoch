---
title: \large How resource abundance and stochasticity affect animals' space-use requirements
subtitle: "Appendix 3: Empirical modeling"
author:
  - name: Stefano Mezzini
    email: stefano.mezzini@ubc.ca
    institute: [biol, braes]
  - name: Simon Wood
    institute: uofe
  - name: E. Patrícia Medici
    institute: [tapir, iucn, escas]
  - name: Michael J. Noonan
    email: michael.noonan@ubc.ca
    institute: [biol, braes, cmps]
institute:
  - biol: Department of Biology, The University of British Columbia Okanagan, Kelowna, British Columbia, Canada.
  - braes: Okanagan Institute for Biodiversity, Resilience, and Ecosystem Services, The University of British Columbia Okanagan, Kelowna, British Columbia, Canada.
  - uofe: School of Mathematics, James Clerk Maxwell Building, University of Edinburgh, Edinburgh, Unted Kingdom.
  - tapir: Lowland Tapir Conservation Initiative (LTCI), Instituto de Pesquisas Ecológicas (IPÊ), Rodovia Dom Pedro I, km 47, Nazaré Paulista, São Paulo 12960-000, Brazil.
  - iucn: IUCN SSC Tapir Specialist Group (TSG), Campo Grande, Brazil.
  - escas: Escola Superior de Conservação Ambiental E Sustentabilidade (ESCAS/IPÊ), Rodovia Dom Pedro I, km 47, Nazaré Paulista, São Paulo 12960-000, Brazil.
  - cmps: Department of Computer Science, Math, Physics, and Statistics, The University of British Columbia Okanagan, Kelowna, British Columbia, Canada.
bibliography: 'hr-resource-stoch.bib'
csl: 'the-american-naturalist.csl'
fontsize: 12pt
header-includes:
    - \usepackage{setspace}\doublespacing # for double-spaced text
    - \usepackage[small]{titlesec} # for smaller font for headings
    - \usepackage{caption} # for more customization of captions
    - \captionsetup[figure]{font=scriptsize} # smaller caption text
    -  \usepackage{hanging} # for hanging indents in references
subparagraph: true # needed for \usepackage[small]{titlesec}
output:
  bookdown::pdf_document2:
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
    toc: false
---

<!-- set default code chunk options -->

```{r setup, echo=FALSE}
hook_chunk <- knitr::knit_hooks$get('chunk')

knitr::knit_hooks$set(chunk = function(x, options) {
  regular_output = hook_chunk(x, options)
  # add latex commands if chunk option singlespacing is TRUE
  if (isTRUE(options$singlespacing)) 
    sprintf("\\singlespacing\n %s \n\\doublespacing", regular_output)
  else
    regular_output
})

knitr::opts_chunk$set(eval = FALSE,         # do not run R code
                      echo = TRUE,          # print R code
                      message = FALSE,      # hide messages
                      comment = '',         # don't add anything before outputs
                      fig.align = 'center', # change figure alignment
                      cache = TRUE,         # cache all chunk outputs
                      singlespacing = TRUE) # use single spacing for code chunks
knitr::opts_knit$set(root.dir = '..')
```

<!-- add custom commands for formulae -->

\newcommand{\e}{\mathbb E}
\newcommand{\var}{\mathbb V}

<!-- have table of contents on pages of its own -->

\newpage

\tableofcontents

\newpage

This appendix illustrates the steps necessary to reproduce the tapir movement analysis and the related figure in the manuscript. The tapir data used here is from the work of @medici_movement_2022 and can be found at the GitHub repository located at [https://github.com/StefanoMezzini/tapirs](https://github.com/StefanoMezzini/tapirs). For ease of reference, we also include the figure below (fig. \@ref(fig:tapir-mw)). Estimating the effects of resource abundance and unpredictability on the tapir's space-use requirements requires us to first estimate the changes in the tapir's space-use requirements (section \@ref(movement), fig. \@ref(fig:tapir-mw)c) and the changes in resource abundance and variance experienced by the tapir (section \@ref(ndvi), figs. \@ref(fig:tapir-mw)a-b) before we can estimate the relationship between resource dynamics and spatial use (section \@ref(final-fig), figs. \@ref(fig:tapir-mw)d-f).

```{r tapir-mw, fig.cap="Seven-day home-range size of a lowland tapir (\\emph{Tapirus terrestris}) in response to changes in mean and variance in resource abundance. (a.) Mean resource abundance, $\\mu(t)$, esimated as the mean NDVI at the locations visited by the tapir. (b.) Varince in resource abundance, $\\sigma^2(t)$, esimated as the average variance in NDVI at the locations visited by the tapir. (c.) Estimated seven-day home range based on the 95\\% utilization quantiles. (d., e.) estimated marginal effects of $\\mu(t)$ and $\\sigma^2(t)$ on home-range size. The model accounted for the marginal effects of $\\mu(t)$ and $\\sigma^2(t)$ and their interaction on mean space-use requirements and the variance around them. (f.) The effect of $\\mu(t)$ does not follow the data closely because $\\e(R)$ and $\\var(R)$ are highly correlated. Consequently, while estimating the effects of $\\e(R)$ and $\\var(R)$ via separate models would allow result in a closer fit, the estimated effects would be inappropriate because they do not disentangle the effects of $\\e(R)$ and $\\var(R)$. See Appendix 3 for additional information. The tapir movement data corresponds to the individual named ``Anna\" from the Cerrado sample of Medici $et~al.$ (2022).", out.width='100%', eval=TRUE, echo=FALSE}
knitr::include_graphics('H:/GitHub/hr-resource-stoch/figures/tapir-example-with-data.png',
                        rel_path = FALSE)
```

To minimize the computational costs of creating this appendix, we load the necessary objects through hidden `R` chunks rather than re-running all the code. Still, those interested in replicating the analyses can do so by using the code in the pdf document or the related `R` Markdown (`Rmd`) document (as well as the `R` scripts). All the packages and source scripts required to run the analyses in this document are listed in the code chunk below. For spatial data, we use the `MODIStsp` package [version 2.0.9, @busetto_modistsp_2016] to download the NDVI rasters, the `terra` package [version 1.7-39, @hijmans_terra_2023] to work with the NDVI rasters, and the `sf` package [version 1.0-8, @pebesma_simple_2018]. We use the `dplyr` [version 1.0.10, @wickham_dplyr_2022], `purrr` [version 0.3.5, @henry_purrr_2022], and `tidyr` [version 1.2.1, @wickham_tidyr_2022] packages for data wrangling and the `lubridate` package [version 1.8.0, @grolemund_dates_2011] for converting calendar dates to decimal dates. Finally, we used the `ctmm` package [version 1.1.0, @fleming_ctmm_2021] and the `mgcv` package [version 1.8-41, @wood_generalized_2017] for modeling and the `ggplot2` [version 3.4.0, @wickham_ggplot2_2016] and `cowplot` [version 1.1.1, @wilke_cowplot_2020] packages for plotting.

\newpage

We start by attaching all necessary packages and custom functions we need:

```{r, eval=TRUE}
getwd() # change working directory or file paths if needed

# attach all necessary packages
library('terra')    # to import and save rasters
library('dplyr')     # for data wrangling
library('purrr')     # for functional programming
library('tidyr')     # for data wrangling
library('ggplot2')   # for fancy plots
library('cowplot')   # for fancy multi-panel plots
library('ctmm')      # for movement modeling
library('mgcv')      # for empirical Bayesian GAMs
library('scam')      # for shape-constrained splines
library('lubridate') # for smoother date wrangling
library('sf')        # for spatial features
library('MODIStsp')  # for downloading NDVI rasters
theme_set(theme_bw()) # change default theme
getwd()

# attach the beta location-scale family written by Simon Wood
source('functions/betals.r')

# source all necessary scripts
source('analysis/figures/default-figure-styling.R') # for color palettes
source('earthdata-login-info.R') # personal login info for EarthData
source('functions/window_hr.R') # function to calculate HRs
```

\newpage

# Modeling the tapir's movement over time {#movement}

\noindent The script `analysis/tapir/tapirs-moving-window.R` estimates the seven-day spatial use of various tapirs from the Brazilian Cerrado. Here, we simplified the code so that it only estimates the spatial use of the tapir in the manuscript, Anna:

```{r}
# import tapir data from https://github.com/StefanoMezzini/tapirs
anna <- readRDS('../tapirs/models/tapirs-final.rds') %>%
  filter(name.short == 'ANNA')
anna_tel <- anna$data[[1]] # telemetry data

# re-project using the appropriate UTM projection for the Brazilian Cerrado
ctmm::projection(anna_tel) <- '+proj=utm +zone=22 +datum=NAD83 +units=m'

# calculate the 7-day home range estimate
window_hr(
  tel = anna_tel,
  window = 7 %#% 'day', # 1 week of data for sufficient sample size
  dt = 1 %#% 'day', # move window over by a single day each time
  fig_path = 'figures',
  rds_path = 'models')
anna_mw <- readRDS('models/tapirs/CE_31_ANNA-window-7-days-dt-1-days.rds')
anna_mw
```

```{r, echo=FALSE, eval=TRUE}
anna <- readRDS('../tapirs/models/tapirs-final.rds') %>%
  filter(name.short == 'ANNA')
anna_tel <- anna$data[[1]] # telemetry data

# projection for the region in the Brazilian Cerrado
ctmm::projection(anna_tel) <- '+proj=utm +zone=22 +datum=NAD83 +units=m'

anna_mw <- readRDS('models/tapirs/CE_31_ANNA-window-7-days-dt-1-days.rds')
anna_mw
```

The `window_hr()` function estimates the tapir's home range using a sliding window approach with a window size of 7 days (using `ctmm`'s `%#%` operator for unit conversions) that starts with the set of days from `r format(as.POSIXct(anna_mw$t_start[1]), format = '%Y-%m-%d')` to `r format(as.POSIXct(anna_mw$t_end[1]), format = '%Y-%m-%d')` (extremes included), then shifts by one day (`dt = 1 %#% 'day'`), repeats the analysis for the next seven-day set (`r format(as.POSIXct(anna_mw$t_start[2]), format = '%Y-%m-%d')` to `r format(as.POSIXct(anna_mw$t_end[2]), format = '%Y-%m-%d')`), and continues doing so until it reaches the last set of days, `r format(as.POSIXct(anna_mw$t_start[nrow(anna_mw)]), format = '%Y-%m-%d')` to `r format(as.POSIXct(anna_mw$t_end[nrow(anna_mw)]), format = '%Y-%m-%d')`. For each set of days, it fits a positional variogram, a continuous-time movement model [@fleming_ctmm_2021], and a utilization distribution via autocorrelated kernel density estimation [@silva_autocorrelationinformed_2022; @noonan_comprehensive_2019]. Finally, it saves an exploratory figure (fig. \@ref(fig:mw)) to the `figures` folder and the tibble of times, telemetries, movement models, utilization distributions, and home range estimates (with 95% confidence intervals) to the `models` folder.

```{r mw, eval=TRUE, echo=FALSE, fig.cap="Exploratory figure created by the $\\tt{window\\_hr()}$ function. Panel $\\mathbf{a.}$ shows the tapir's GPS locations, while panel $\\mathbf{b.}$ shows the seven-day home range estimates (95\\% and 50\\% utilization quantiles) with 95\\% confidence intervals.", out.width='\\textwidth'}
knitr::include_graphics('H:/GitHub/hr-resource-stoch/figures/tapirs/CE_31_ANNA-window-7-days-dt-1-days.png', rel_path = FALSE)
```

\newpage

# Modeling $\e(R)$ and $\var(R)$ over time {#ndvi}

To estimate the resources in the tapir's habitat, we used satellite-measured Normalized Difference Vegetation Index [NDVI, see @pettorelli_using_2005; @pettorelli_normalized_2011]. We downloaded the data using the `MODIStsp` `R` package with the following code:

```{r}
anna_ud <- anna$akde[[1]] # extract the tapir's utilization distribution

bbox <-
  SpatialPolygonsDataFrame.UD(anna_ud, # convert to a spatial object
                              level.UD = 0.9995, # utilization quantile
                              level = 0) %>% # no CIs
  st_as_sf() %>%
  st_transform(crs = '+proj=longlat') %>%
  st_bbox()

# download NDVI rasters (if needed, create all necessary folders first)
MODIStsp(gui = FALSE, # do not use the browser GUI, only run in R
         out_folder = 'data/ndvi-rasters/tapir-anna',
         selprod = 'Vegetation Indexes_16Days_250m (M*D13Q1)',
         prod_version = '061', # 2022 raster version
         bandsel = 'NDVI', # NDVI layer only
         sensor = 'Terra', # only terrestrial values, ignore water
         user = USERNAME, # Earthdata username for urs.earthdata.nasa.gov
         password = PASSWORD, # your Earthdata password
         start_date = format(min(anna_tel$timestamp) - 16, '%Y.%m.%d'),
         end_date = format(max(anna_tel$timestamp) + 16, '%Y.%m.%d'),
         spatmeth = 'bbox', # use a bounding box for the extent
         bbox = bbox, # spatial file for raster extent
         out_projsel = 'User Defined', # use specified projection
         output_proj = '+proj=longlat', # download unprojected raster
         resampling = 'bilinear', # raster resampling method for new proj
         delete_hdf = TRUE, # delete HDF files after download is complete
         scale_val = TRUE, # convert from integers to floats within [-1, 1]
         out_format = 'GTiff', # output format
         verbose = TRUE) # print processing messages

# save NDVI data as an rds file of a tibble
list.files(path = 'data/ndvi-rasters/tapir-anna/VI_16Days_250m_v61/NDVI/',
           pattern = '.tif', full.names = TRUE) %>%
  rast() %>% # import all rasters as a single stack
  as.data.frame(xy = TRUE) %>% # convert to a data frame
  pivot_longer(-c(x, y)) %>% # change to long format (x, y, name, value)
  transmute(long = x, # rename x column
            lat = y, # rename y column
            date = substr(name, # change name to a date
                          start = nchar('MOD13Q1_NDVI_x'),
                          stop = nchar(name)) %>%
              as.Date(format = '%Y_%j'), # format is year_julian date
            ndvi = value, # rename value column
            dec_date = decimal_date(date)) %>%
  saveRDS('data/ndvi-rasters/tapir-anna/tapir-anna-data.rds')

# import NDVI data
anna_ndvi <-
  readRDS('data/ndvi-rasters/tapir-anna/tapir-anna-data.rds') %>%
  mutate(dec_date = decimal_date(date))
anna_ndvi
```

```{r, echo=FALSE, eval=TRUE}
# import NDVI data
anna_ndvi <-
  readRDS('data/ndvi-rasters/tapir-anna/tapir-anna-data.rds') %>%
  mutate(dec_date = decimal_date(date))
anna_ndvi
```

We removed the raster for 2017-12-19 because the values were unusually low for the region. We hypothesize the change in NDVI was drastic, temporary, and widespread because of a sudden flood (which is common for the Cerrado):

<!-- using echo = TRUE and eval = TRUE because this needs to be both visible and evaluated -->

```{r, echo=TRUE, eval=TRUE, fig.height=8, fig.width=10, out.width='100%', }
anna_ndvi %>%
  filter(date >= as.Date('2017-08-29'), date <= as.Date('2018-04-07')) %>%
  ggplot() +
  facet_wrap(~ date, nrow = 3) + # a raster for each date
  coord_equal() + # keep the scaling of x and y equal
  geom_tile(aes(long, lat, fill = ndvi)) +
  scale_x_continuous(NULL, breaks = NULL, expand = c(0, 0)) +
  scale_y_continuous(NULL, breaks = NULL, expand = c(0, 0)) +
  scale_fill_gradientn('NDVI', colours = ndvi_pal, limits = c(-1, 1)) +
  theme(legend.position = 'top')

anna_ndvi <- filter(anna_ndvi, date != '2017-12-19') # remove bad values
```

Next, we estimate the mean and variance in NDVI using a Generalized Additive Model for location and scale [GAMLS: @stasinopoulos_generalized_2007]. Ideally, we would model NDVI using a family of distributions that accounts for the fact that NDVI cannot be less than -1 or greater than 1, but no such family is available in the `mgcv` package. However, since the NDVI data is far from 0 (see the histogram below), we decided to keep NDVI unscaled. This prevents the model from predicting values that correspond to water or snow (which are not expected to occur in the study area). Mathematically, this approach would be comparable to predicting in a Bayesian framework with a prior with zero probability for any NDVI values below zero. In environments where values below zero are probable, one could use the beta family after applying the linear transformation $$y^* = \frac{y + 1}{2},$$ where $y$ is the original NDVI value (between -1 and 1) and $y^*$ is the NDVI value scaled between 0 and 1.

We fit the beta GAMLS via the `mgcv` package (note `family = betals()` in the code chunk below). The `betals` family accepts a list of two predictors: one for the mean parameter, $\mu$, and one for the scale parameter, $\phi$, and it uses logit link functions for both parameters (see fig. \@ref(fig:gamls-terms)). The variance of the distribution is a function of both parameters: $\sigma^2 = \mu (1 - \mu) \phi$.

```{r, echo=FALSE, eval=TRUE, fig.height=2}
ggplot(anna_ndvi, aes(ndvi)) +
  geom_histogram(na.rm = TRUE) +
  labs(x = 'NDVI', y = 'Count') +
  xlim(c(-1, 1)) +
  theme_bw()
```

\clearpage

```{r}
m_ndvi <-
  gam(list(
    # mean predictor
    ndvi ~ # not scaling because range is in (0, 1)
      s(long, lat, bs = 'ds', k = 20) + # mean over space
      s(dec_date, bs = 'tp', k = 20),   # high k to account for adaptions
    # scale predictor (sigma2 = mu * (1 - mu) * scale)
    ~
      s(long, lat, bs = 'ds', k = 10) + # scale over space
      s(dec_date, bs = 'tp', k = 10)),  # scale over time
    family = betals(),
    data = anna_ndvi,
    method = 'REML') # REstricted Maximum Likelihood 
```

Note that when fitting location-scale GAMs, one should pay particular attention to the number of knots used for each smooth term. While using a penalized maximum likelihood method such as REML (`method = 'REML'`) helps avoid over-fitting the model, finding the right balance between each of the `k` values is crucial. Excessively smooth terms for the mean can inflate the scale term (fig. \@ref(fig:undersmooth)), while excessively wiggly terms for the mean can cause the scale to be under-estimated (fig. \@ref(fig:oversmooth)). Ultimately, each of the `k` values should be decided in such a way as to mimic the animal's responsiveness, adaptability, motility, and memory (or ability to predict cycles or events). If one is unsure where to start from, keeping the `k` for the scale terms below half the `k` for the mean terms is a good starting point.

\clearpage

```{r gamls-terms, echo=FALSE, eval=TRUE, fig.height=8, fig.cap="Estimated spatiotemporal trends in mean and scale parameters using the model detailed in the code chunk above. Estimates are provided on the logit link scale. The estimated degrees of freedom for each term can be seen in parentheses in the title of the spatial terms and the y-axis labels of the temporal terms. Dashed lines inticate the 95\\% credible intervals for the temporal terms.", fig.pos='!h'}
m_ndvi <- readRDS('models/tapirs/CE_31_ANNA-mgcv-ndvi-betals.rds')
plot(m_ndvi, pages = 1, scheme = 3, n = 250, scale = 0)
```

```{r}
gam(list(
  # mean predictor (default ks are too small)
  ndvi ~ s(long, lat, bs = 'ds', k = 10) + s(dec_date, bs = 'tp', k = 10),
  # scale predictor (excessively high k)
  ~ s(long, lat, bs = 'ds', k = 20) + s(dec_date, bs = 'tp', k = 20)),
  family = betals(), data = anna_ndvi, method = 'REML') %>%
  plot(pages = 1, scheme = 3, n = 250, scale = 0)

gam(list(
  # mean predictor (ks too large)
  ndvi ~ s(long, lat, bs = 'ds', k = 50) +
    s(dec_date, bs = 'tp', k = n_distinct(anna_ndvi$dec_date)),
  # scale predictor (ks too small)
  ~ s(long, lat, bs = 'ds', k = 5) + s(dec_date, bs = 'tp', k = 5)),
  family = betals(), data = anna_ndvi, method = 'REML') %>%
  plot(pages = 1, scheme = 3, n = 250, scale = 0)
```

\clearpage

```{r undersmooth, fig.cap="Estimated mean and scale parameters with excessively small basis size $\\tt{k}$ for the mean's smooth terms and excessively large for the scale's smooth terms. The estimated degrees of freedom for each term can be seen in parentheses in the title of the spatial terms and the y-axis labels of the temporal terms. Dashed lines inticate the 95\\% credible intervals for the temporal terms.", eval=TRUE, fig.height=8, fig.pos='!h', echo=FALSE}
gam(list(
  # mean predictor (default ks are too small)
  ndvi ~ s(long, lat, bs = 'ds', k = 10) + s(dec_date, bs = 'tp', k = 10),
  # scale predictor (excessively high k)
  ~ s(long, lat, bs = 'ds', k = 20) + s(dec_date, bs = 'tp', k = 20)),
  family = betals(), data = anna_ndvi, method = 'REML') %>%
  plot(pages = 1, scheme = 3, n = 250, scale = 0)
```

\clearpage

```{r oversmooth, fig.cap="Estimated mean and scale parameters in NDVI with excessively large basis size $\\tt{k}$ for the smooth term of time ($\\tt{dec\\_date}$) for the mean in NDVI and excessively low for the variance temporal smooth term. The estimated degrees of freedom for each term can be seen in parentheses in the title of the spatial terms and the y-axis labels of the temporal terms. Dashed lines inticate the 95\\% credible intervals for the temporal terms.", eval=TRUE, fig.height=8, fig.pos='!h', echo=FALSE}
gam(list(
  # mean predictor (ks too large)
  ndvi ~ s(long, lat, bs = 'ds', k = 50) +
    s(dec_date, bs = 'tp', k = n_distinct(anna_ndvi$dec_date)),
  # scale predictor (ks too small)
  ~ s(long, lat, bs = 'ds', k = 5) + s(dec_date, bs = 'tp', k = 5)),
  family = betals(), data = anna_ndvi, method = 'REML') %>%
  plot(pages = 1, scheme = 3, n = 250, scale = 0)
```

\newpage

# Modeling the effects of $\e(R)$ and $\var(R)$ on space-use requirements {#final-fig}

We start by predicting the mean and variance in NDVI experienced by the tapir in the known positions using the beta GAMLS.

```{r, eval=TRUE}
anna_tel <-
  data.frame(anna_tel) %>% # convert telemetry to data frame
  rename(long = longitude, lat = latitude) %>%
  mutate(dec_date = decimal_date(timestamp)) %>% # needed for predictions
  bind_cols(., # bind telemetry to predictions
            predict(m_ndvi, newdata = ., type = 'response',
                    se.fit = FALSE) %>%
              data.frame() %>% # convert list of predictions to data frame
              # didn't scale NDVI to [0, 1], so no need to back-transform
              transmute(mu = X1, sigma2 = X1 * (1 - X1) * X2)) %>%
  as_tibble()
```

Next, we can estimate the mean and variance in NDVI for each 7-day period by taking the average for the GPS locations within each period.

```{r, eval=TRUE}
tapir <-
  readRDS('models/tapirs/CE_31_ANNA-window-7-days-dt-1-days.rds') %>%
  mutate(est = map(dataset,
                   \(.d) filter(anna_tel, timestamp %in% .d$timestamp)),
         mu = map_dbl(est, \(.d) mean(.d$mu)),
         sigma2 = map_dbl(est, \(.d) mean(.d$sigma2))) %>%
  select(t_center, mu, sigma2, hr_lwr_95, hr_est_95, hr_upr_95) %>%
  pivot_longer(c(hr_lwr_95, hr_est_95, hr_upr_95),
               names_to = c('.value', 'quantile'),
               names_pattern = '(.+)_(.+)') %>%
  mutate(t_center = as.POSIXct(t_center),
         quantile = paste0(quantile, '%'))
```

We now have all we need to create the left side of figure \@ref(fig:tapir-mw).

```{r, eval=TRUE, fig.height=4, fig.width=12, out.width='\\linewidth'}
theme_set(theme_bw()) # need to set the theme again for some reason

# create the figure
date_labs <- range(anna_tel$timestamp) %>% as.Date()
YLIMS <- c(0, 13)

# axis labels (spaces in hr_lab to avoid overlap with the plot label)
# removed unicode characters to avoid knitting errors
e_r <- 'Resource abundance'
v_r <- 'Resource stochasticity'
hr_lab <- expression('7-day'~home~range~size~(km^2)~'   ')

l_grobs <-
  lapply(
    list(
      # mean
      ggplot(tapir, aes(t_center, mu)) +
        geom_line(color = pal[1]) +
        labs(x = NULL, y = e_r),
      # variance
      ggplot(tapir, aes(t_center, sigma2)) +
        geom_line(color = pal[2]) +
        labs(x = NULL, y = v_r),
      # 95% home range
      ggplot(tapir, aes(t_center, hr_est)) +
        geom_line(color = pal[3]) +
        labs(x = NULL, y = hr_lab)),
    as_grob) # convert to grid graphical objects (grobs)

# align left margins of all plots
aligned_widths <- align_margin(map(l_grobs,
                                   function(x) {x$widths}), 'first')

# Setting the dimensions of plots to the aligned dimensions
for (i in seq_along(l_grobs)) {
  l_grobs[[i]]$widths <- aligned_widths[[i]]
}

# Draw aligned plots
plot_grid(plotlist = l_grobs, nrow = 1, labels = c('a.', 'b.', 'c.'))
```

To create the right side of the figure, we will need to estimate the effects of $\e(R)$ and $\var(R)$ on the tapir's space-use requirements. To do this, we fit a GAM to the the tapir's 7-day home range estimates using the mean and variance in NDVI as predictors. However, since the two predictors are highly correlated, using a regular GAM causes the effects to be non-monotonic (after strongly restricting `k` to avoid over-fitting; see fig. \@ref(fig:hr-gam)).

```{r hr-gam, eval=TRUE, fig.pos='!h', fig.height=3, fig.cap="Marginal effects of $\\mu(t)$ and $\\sigma^2(t)$ on the tapir's space-use requirements (on the log link scale) using a GAM with no shape constraints. The estimated degrees of freedom for each term can be seen in parentheses in the y-axis labels. Dashed lines inticate the 95\\% credible intervals for the temporal terms."}
gam(hr_est ~ s(mu,  k = 3) + s(sigma2, k = 3), family = Gamma('log'),
    data = tapir) %>%
  plot(pages = 1, scheme = 3)
```

\clearpage

Thus, we use shape-constrained splines to inform the model about the shape we expect the terms to have while also imposing monotonicity.

```{r hr-scam, eval=TRUE, fig.pos='!h', fig.height=3, fig.cap="Marginal effects of $\\mu(t)$ and $\\sigma^2(t)$ on the tapir's space-use requirements (on the log link scale) using a shape-constrained GAM. The estimated degrees of freedom for each term can be seen in parentheses in the y-axis labels. Dashed lines inticate the 95\\% credible intervals for the temporal terms."}
m <- scam(hr_est ~
            s(mu, bs = 'mpd', k = 4) + # monotone decreasing p-spline
            s(sigma2, bs = 'mpi', k = 4), # monotone increasing p-spline
          family = Gamma('log'),
          data = tapir)
plot(m, pages = 1, scheme = 3)
```

Finally, we can create the predictions from the shape-constrained GAM.

```{r, eval=TRUE, fig.height=4, fig.width=12, out.width='\\linewidth'}
theme_set(theme_bw()) # need to set the theme again for some reason

# predict marginal effects for each term
preds <- tibble(mu = gratia:::seq_min_max(tapir$mu, n = 250),
                sigma2 = gratia:::seq_min_max(tapir$sigma2, n = 250)) %>%
  bind_cols(
    # predictions for the marginal effect of mu
    predict(m, newdata = ., terms = 's(mu)', type = 'link',
            se.fit = TRUE) %>%
      as.data.frame() %>% # convert list to data frame
      transmute(hr_mu_est = exp(fit), # transform to the response scale
                hr_mu_lwr = exp(fit - 1.96 * se.fit), # 95% cred. intervals
                hr_mu_upr = exp(fit + 1.96 * se.fit)),
    # predictions for the marginal effect of sigma2
    predict(m, newdata = ., terms = 's(sigma2)', type = 'link',
            se.fit = TRUE) %>%
      as.data.frame() %>%
      transmute(hr_sigma2_est = exp(fit),
                hr_sigma2_lwr = exp(fit - 1.96 * se.fit),
                hr_sigma2_upr = exp(fit + 1.96 * se.fit)))

p_d <- ggplot() +
  coord_cartesian(ylim = c(0, 12.5)) +
  geom_point(aes(mu, hr_est), tapir, color = pal[3], alpha = 0.5) +
  geom_ribbon(aes(mu, ymin = hr_mu_lwr, ymax = hr_mu_upr), preds,
              fill = pal[1], alpha = 0.3) +
  geom_line(aes(mu, hr_mu_est), preds, color = pal[1]) +
  xlab(e_r) +
  scale_y_continuous(hr_lab)

p_e <- ggplot() +
  coord_cartesian(ylim = c(0, 12.5)) +
  geom_point(aes(sigma2, hr_est), tapir, color = pal[3], alpha = 0.5) +
  geom_ribbon(aes(sigma2, ymin = hr_sigma2_lwr, ymax = hr_sigma2_upr),
              preds, fill = pal[2], alpha = 0.3) +
  geom_line(aes(sigma2, hr_sigma2_est), preds, color = pal[2]) +
  xlab(v_r) +
  scale_y_continuous(hr_lab)

p_f <- ggplot(tapir) +
  geom_point(aes(mu, sigma2), alpha = 0.5) +
  labs(x = e_r, y = v_r)

r_grobs <- map(list(p_d, p_e, p_f), as_grob)

# align right margins of all plots
aligned_widths <- align_margin(map(r_grobs,
                                   function(x) {x$widths}), 'first')

# Setting the dimensions of plots to the aligned dimensions
for (i in seq_along(r_grobs)) {
  r_grobs[[i]]$widths <- aligned_widths[[i]]
}

plot_grid(plotlist = r_grobs, ncol = 3, labels = c('d.', 'e.', 'f.'))
```

\clearpage

# References {-}

\hangparas{1em}{1} <!-- indent all lines but the first -->
